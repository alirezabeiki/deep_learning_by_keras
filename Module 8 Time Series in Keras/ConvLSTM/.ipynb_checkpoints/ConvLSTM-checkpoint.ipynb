{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Models\n",
    "\n",
    "We create a model which take as input movies of shape (n_frames, width, height, channels) and returns a movie of identical shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(\n",
    "            shape=(None, 40, 40, 1)\n",
    "        ),  # Variable-length sequence of 40x40x1 frames\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv3D(\n",
    "            filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "seq.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate artificial data\n",
    "\n",
    "Generate movies with 3 to 7 moving squares inside. The squares are of shape 1x1 or 2x2 pixels, and move linearly over time. For convenience, we first create movies with bigger width and height (80x80) and at the end we select a 40x40 window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 15, 40, 40, 1)\n",
      "(1200, 15, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[\n",
    "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
    "                ] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the model to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1) ** np.random.randint(0, 2)\n",
    "                    noisy_movies[\n",
    "                        i,\n",
    "                        t,\n",
    "                        x_shift - w - 1 : x_shift + w + 1,\n",
    "                        y_shift - w - 1 : y_shift + w + 1,\n",
    "                        0,\n",
    "                    ] += (noise_f * 0.1)\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[\n",
    "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
    "                ] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "print(noisy_movies.shape)\n",
    "print(shifted_movies.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-53269d6e7336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# display original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_movies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n = 15 # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "    plt.imshow(noisy_movies.shape[1,i,:,:,:])\n",
    "    plt.show()\n",
    "    \n",
    "'''\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(noisy_movies.shape[1,i,:,:,:])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 - 917s - loss: 0.8426 - val_loss: 0.6807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fccbf7465d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1  # In practice, you would need hundreds of epochs.\n",
    "\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "seq.fit(\n",
    "    noisy_movies[:1000],\n",
    "    shifted_movies[:1000],\n",
    "    batch_size=10,\n",
    "    epochs=epochs,\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on one movie\n",
    "\n",
    "Feed it with the first 7 positions and then predict the new positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcc04b06200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "movie_index = 1004\n",
    "test_movie = noisy_movies[movie_index]\n",
    "\n",
    "# Start from first 7 frames\n",
    "track = test_movie[:7, ::, ::, ::]\n",
    "\n",
    "# Predict 16 frames\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
